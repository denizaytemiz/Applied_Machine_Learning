# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X0mHln2sBlqklOV0OiMl5KdW_2xIKRTb
"""

#import libraries
import pandas as pd
import numpy as np
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn import metrics
import matplotlib.pyplot as plt
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import roc_auc_score
import random

#load data
df = pd.read_excel('ccpp.xlsx')

df

#scaling dataframe
scaler = preprocessing.StandardScaler()

df_scaled = scaler.fit_transform(df.to_numpy())

df_scaled = pd.DataFrame(df_scaled, columns=[
  'ID', 'AT', 'V', 'AP', 'RH', 'TG'])

df_scaled

# column ID and TG dont need to be scaled so I dropped them and added them from dataframe df
df_scaled = df_scaled.drop('TG', axis= 'columns')
df_scaled = df_scaled.drop('ID', axis= 'columns')

extracted_col1 = df["TG"]
extracted_col2 = df["ID"]
df_scaled = df_scaled.join(extracted_col1)
df_scaled = df_scaled.join(extracted_col2)

df_scaled

# ID is droped since it is not a feauture and TG is the target variable
X = df_scaled.drop(['ID','TG'], axis='columns')
y = df_scaled['TG']

# split into train test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)

# Commented out IPython magic to ensure Python compatibility.
# Solve the problem using an artificial neural network
regpenalty = 0.001
hl = (5, 5)
clf = MLPClassifier(hidden_layer_sizes=hl, activation='tanh', solver='adam', \
alpha=regpenalty, early_stopping=True, validation_fraction=0.42)
clf.fit(X_train,y_train)
annPredY = clf.predict(X_test)
print("\n\rANN: %d mislabeled out of %d points"
# % ((y_test != annPredY).sum(), X_test.shape[0]))
print(metrics.confusion_matrix(y_test, annPredY))
trainingLoss = np.asarray(clf.loss_curve_)
validationLoss = np.sqrt(1 - np.asarray(clf.validation_scores_))
factor = trainingLoss[1] / validationLoss[1]
validationLoss = validationLoss*factor
# create figure and axis objects with subplots()
xlabel = "epochs (hl=" + str(hl) + ")"
fig,ax = plt.subplots()
ax.plot(trainingLoss, color="blue")
ax.set_xlabel(xlabel,fontsize=10)
ax.set_ylabel("training loss",color="blue",fontsize=10)
ax2=ax.twinx()
ax2.plot(validationLoss,color="red")
ax2.set_ylabel("validation score",color="red",fontsize=10)
plt.show()

#finding best 10 and worst 10 architectures using AUC as metric

# hidden layers are defined for every possible matching of numbers from 1 to 3 
# one_tuple stores 1-tuples as 1,2,3 whereas two_tuples store every possible combination of numbers in the range
# as (1,2), (3,2) etc. Likewise three_tuple is the 3 numbered version of it as (2,1,3), (3,1,1) etc
# therefore total stores all these possible hidden layer architectures we are going to train and 
# evaluate performance of

from itertools import product
total = [(1,1),(1,2),(1,3),(1,4),(1,5),(1,6),(1,7),(1,8),(1,9),(2,1),(2,2),(2,3),(2,4),(2,5),(2,6),(2,7),(2,8),(2,9),(3,1),(3,2),(3,3),(3,4),(3,5),(3,6),(3,7),(3,8),(3,9)]


# all possible activation states
activations = ('relu', 'identity', 'tanh')

# creating empty dataframe to analyze the results later

results = pd.DataFrame(data=None, columns=['hidden layers',
                                           'activation', 'error_rate', 'auroc']) 
# trying all possible combinations of hidden layers and
# activation modes
# adam is selected as solver as default
for i in total:
  for j in activations:
    alphas = 0.001
    clf = MLPClassifier(solver='adam', 
                        activation = j,
                        alpha = alphas, 
                        hidden_layer_sizes = i, 
                        early_stopping = True, 
                        validation_fraction=0.42)
    
    # Train the model with current values
    clf.fit(X_train, y_train)

    # test model on test set
    predictions = clf.predict(X_test)
    actual = y_test

    # find out misclassification error
    # Misclassification Rate = # incorrect predictions / # total predictions
    error_rate = ((predictions == actual).value_counts()[False]/actual.count())


    # Determine the AUROC
    auroc = roc_auc_score(actual, predictions)

    # print architecture properties
    print("Running ", str(i), " hidden layers for the solver: ", str(j))

    # Store all results for later
    results = results.append({'hidden layers': i, 
                              'activation': j, 
                              'error_rate': error_rate,
                              'auroc': auroc
                              }, ignore_index=True)

results

table = results.to_excel("output.xlsx")

## best results dependong on error_rate
df1=results.sort_values(by=['error_rate'])

df1.head(10)

## worst results dependong on error_rate
df2 = results.sort_values(by='error_rate', ascending=False)

df2.head(10)

#wost results for auroc
df3 = results.sort_values(by=['auroc'])

df3.head(10)

## best results dependong on auroc
df4 = results.sort_values(by='auroc', ascending=False)

df4.head(10)